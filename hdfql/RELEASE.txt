=====================
2021/APR/21
=====================
NEWS
- Released HDFql version 2.4.0
- Added support for user-defined block of data stored within an HDF5 file in a space reserved for this purpose
- Improved memory footprint to maintain an open HDF5 file (it now takes ~3 KB to maintain an open file (before it was taking ~30 KB) - this can be especially relevant when maintaining thousands of open files at the same time)
- Replaced the readline library by the editline library in HDFqlCLI (command-line interface) (in Linux and macOS)
- Updated reference manual

CHANGES
- Added "SHOW USERBLOCK" operation (to enable showing a user-defined block of data stored within an HDF5 file in a space reserved for this purpose)
- Added "SHOW USERBLOCK SIZE" operation (to enable showing the size (in bytes) of a user-defined block of data stored within an HDF5 file in a space reserved for this purpose)
- Added "LIKE" option in the "SHOW DIRECTORY" operation (to enable retrieving directory names recursively (i.e. within directories and subdirectories) and/or filtered by a user-defined regular expression)
- Added "LIKE" option in the "SHOW FILE" operation (to enable retrieving file names recursively (i.e. within directories and subdirectories) and/or filtered by a user-defined regular expression)
- Added "BY NAME" option in the "SHOW FILE VALIDITY", "SHOW TYPE", "SHOW DATA TYPE", "SHOW ENDIANNESS", "SHOW CHARSET", "SHOW STORAGE TYPE", "SHOW STORAGE ALLOCATION", "SHOW ORDER", "SHOW FILL TYPE", "SHOW EXECUTE STATUS", "SHOW LIBRARY BOUNDS", "SHOW ATOMIC", "SHOW FLUSH" and "SHOW DEBUG" operations (to get the result of an operation as a name (i.e. string) instead of a number - e.g. when executing "SHOW TYPE my_object BY NAME", where "my_object" is an object of type dataset, it will return "DATASET" instead of 8 (i.e. the constant number that represents an object of type dataset))
- Added support for writing/reading values into/from a compound dataset/attribute using a variable that is an object of a (user-defined) class (in the Java wrapper)
- Added "HDFQL_FILL_NEVER" constant
- Updated "CREATE FILE" operation (to enable specifying a user-defined block of data that an HDF5 file may store in a space reserved for this purpose)
- Changed maximum number of variables that can be registered at any given time to 5 in order to increase performance (previously the maximum number was 8, which was unnecessarily high)
- Renamed "HDFQL_FILL_USER_DEFINED" constant to "HDFQL_FILL_DEFINED"

FIXES
- Fixed crash when registering a variable (through the "hdfql_variable_register" or "hdfql_variable_transient_register" functions) with a dimension size equal to zero (in the Java wrapper) - thanks to Gerhard for reporting this!

ISSUES
- The "FROM" redirecting option does not work properly when inserting variable-length data from memory into a dataset/attribute (in the Java, Python, C#, Fortran and R wrappers)
- The "WHERE" option (in the "SHOW" operation) does not work properly
- The writing/reading of a compound dataset/attribute does not support a per member operation (i.e. currently it only supports writing/reading all members of a compound)
- The writing of a compound dataset/attribute does not support direct values (e.g. "INSERT INTO my_compound VALUES(10, dummy, 5.6)")
- The "TOP", "BOTTOM", "FROM TO" and "STEP" post-processing options do not support compound datasets/attributes



=====================
2021/FEB/10
=====================
NEWS
- Released HDFql version 2.3.0
- Added support for writing/reading values into/from datasets/attributes from/into EXCEL files (with no EXCEL dependency or OLE automation) - thanks to Dmytro for sponsoring HDFql with a free LibXL license to handle EXCEL files!
- Improved performance and memory footprint when reading values from datasets/attributes of data type variable-length into a cursor (e.g. given a dataset of data type VARINT of three dimensions (size 10x1024x1024) where each element has between 0 and 10 values, it is 2x faster and 3x less memory consuming to read the dataset into a cursor in comparison with previous versions of HDFql)
- Improved performance of the Java wrapper when writing/reading values into/from datasets/attributes from/into memory (e.g. given a dataset of data type INT of three dimensions (size 100x1024x1024), it is 2x faster to write values from memory and 4x faster to read values into memory in comparison with previous versions of the wrapper)
- Linked HDFqlCLI (command-line interface) against the readline static library (instead of the shared library) to avoid dependency issues when launching it in newer Linux and macOS versions - thanks to Quang (Ontario Institute for Cancer Research, Canada) for testing it!
- Updated help functionality in HDFqlCLI (command-line interface)
- Updated reference manual
- Updated HDF5 library in use to 1.8.22 (previously HDFql was using version 1.8.21)

CHANGES
- Added "SET PLUGIN PATH" operation (to enable setting the path where plugins (in the form of shared libraries) are searched for and dynamically loaded by HDFql/HDF5 library)
- Added "SHOW PLUGIN PATH" operation (to enable showing the path where plugins (in the form of shared libraries) are searched for and dynamically loaded by HDFql/HDF5 library)
- Added "AND USE" option in the "CREATE DIRECTORY" operation (to enable using (i.e. opening) a directory after being successfully created - syntactic sugar)
- Added "AND USE" option in the "CREATE FILE" operation (to enable using (i.e. opening) an HDF5 file after being successfully created - syntactic sugar)
- Added "AND USE" option in the "CREATE GROUP" operation (to enable using (i.e. opening) a group after being successfully created - syntactic sugar)
- Added "NO FILL" option in the "CREATE DATASET" operation (to disable setting/writing (default) fill values into a dataset)
- Added "NO VALUES" option in the "INSERT" and "SELECT" operations (to enable writing/reading no values by the MPI process in question (which may be useful in certain situations) only forcing it to participate in the operation (as it is mandatory that all MPI processes participate collectively when working in a parallel way))
- Added "SKIP" option in the "FROM [TEXT | BINARY | EXCEL] FILE" redirecting option (to enable skipping a certain number of initial lines in case of an input text file, cells in the sheet in case of an EXCEL file or bytes in case of an input binary file - which may be useful when the input file contains, e.g., an header that does not need to be taken into consideration)
- Added "HDFQL_MIXED_ENDIAN" constant
- Added "HDFQL_ERROR_NOT_SPECIFIED" constant
- Added "HDFQL_ERROR_INVALID_NAME" constant
- Added "HDFQL_ERROR_INVALID_SELECTION" constant
- Updated "SHOW ENDIANNESS" operation (to enable showing endianness of members of a compound dataset/attribute)
- Updated "SHOW CHARSET" operation (to enable showing charset of members of a compound dataset/attribute)
- Updated "hdfql_variable_*" functions to accept C++ standard array and vector objects as a parameter (alleviating the user from calling their "data" function to get the underlying memory address) (in the C++ wrapper)
- Updated "hdfql_execute" function to accept C++ standard stringstream objects as a parameter (alleviating the user from calling their "str" function to get the underlying memory address) (in the C++ wrapper)
- Changed "CREATE FILE", "USE FILE", "INSERT" and "SELECT" operations (in case of working in a parallel way, use "IN PARALLEL" keyword - instead of just "PARALLEL" - and specify it after the object - i.e. file, dataset or attribute - that the operation refers to)
- Renamed "LIMIT" option to "MAX" (in the "INTO MEMORY" and "FROM MEMORY" redirecting options)
- Renamed "cursorGetTinyInt", "subcursorGetTinyInt", "cursorGetUnsignedTinyInt", "subcursorGetUnsignedTinyInt", "cursorGetSmallInt", "subcursorGetSmallInt", "cursorGetUnsignedSmallInt", "subcursorGetUnsignedSmallInt", "cursorGetBigInt", "subcursorGetBigInt", "cursorGetUnsignedBigInt" and "subcursorGetUnsignedBigInt" functions/methods to "cursorGetTinyint", "subcursorGetTinyint", "cursorGetUnsignedTinyint", "subcursorGetUnsignedTinyint", "cursorGetSmallint", "subcursorGetSmallint", "cursorGetUnsignedSmallint", "subcursorGetUnsignedSmallint", "cursorGetBigint", "subcursorGetBigint", "cursorGetUnsignedBigint" and "subcursorGetUnsignedBigint" respectively (in the C++ and Java wrappers)
- Renamed "CursorGetTinyInt", "SubcursorGetTinyInt", "CursorGetUnsignedTinyInt", "SubcursorGetUnsignedTinyInt", "CursorGetSmallInt", "SubcursorGetSmallInt", "CursorGetUnsignedSmallInt", "SubcursorGetUnsignedSmallInt", "CursorGetBigInt", "SubcursorGetBigInt", "CursorGetUnsignedBigInt" and "SubcursorGetUnsignedBigInt" methods to "CursorGetTinyint", "SubcursorGetTinyint", "CursorGetUnsignedTinyint", "SubcursorGetUnsignedTinyint", "CursorGetSmallint", "SubcursorGetSmallint", "CursorGetUnsignedSmallint", "SubcursorGetUnsignedSmallint", "CursorGetBigint", "SubcursorGetBigint", "CursorGetUnsignedBigint" and "SubcursorGetUnsignedBigint" respectively (in the C# wrapper)
- Renamed "TinyInt", "UnsignedTinyInt", "SmallInt", "UnsignedSmallInt", "BigInt", "UnsignedBigInt", "VarTinyInt", "UnsignedVarTinyInt", "VarSmallInt", "UnsignedVarSmallInt", "VarInt", "UnsignedVarInt", "VarBigInt", "UnsignedVarBigInt", "VarFloat", "VarDouble", "VarChar" and "BitField" constants to "Tinyint", "UnsignedTinyint", "Smallint", "UnsignedSmallint", "Bigint", "UnsignedBigint", "VarTinyint", "UnsignedVarTinyint", "VarSmallint", "UnsignedVarSmallint", "Varint", "UnsignedVarint", "VarBigint", "UnsignedVarBigint", "Varfloat", "Vardouble", "Varchar" and "Bitfield" respectively (in the C++ and C# wrappers)
- Removed "hdfql_cursor_get_size" and "hdfql_subcursor_get_size" functions (as these were of little/no usage)

FIXES
- Fixed issue (introduced in version 2.2.0) when cloning a cursor (using the "hdfql_cursor_clone" function) not setting the cloned cursor with the proper data type
- Fixed issue when writing values into a compound dataset/attribute not working properly with text files (e.g. "INSERT INTO my_compound VALUES FROM TEXT FILE my_file.txt") and binary files (e.g. "INSERT INTO my_compound VALUES FROM BINARY FILE my_file.bin") - thanks to Quang (Ontario Institute for Cancer Research, Canada) for testing it!
- Fixed issue when writing values into a compound dataset/attribute that has a member of data type CHAR with a size greater than one followed by another member not working properly
- Fixed issue of a variable registered in a transient way (through the "hdfql_variable_transient_register" function) not being automatically unregistered after the execution of a script that uses it (through the "FROM MEMORY" redirecting option)
- Fixed issue when reading a dataset/attribute of data type CHAR with a size greater than one and redirecting results into memory not working properly (in the R wrapper)
- Fixed crash when registering a variable (through the "hdfql_variable_register" or "hdfql_variable_transient_register" functions) that cannot be pinned by the C# Garbage Collector (in the C# wrapper)
- Fixed crash when writing values into a dataset in a parallel way and no HDF5 file is in use
- Fixed crash when writing/reading values into/from a dataset using a hyperslab with a count set to 0 and an undefined block (e.g. when executing "INSERT INTO my_dataset(::0:)")
- Fixed crash when reading an empty dataset/attribute of data type variable-length with the debug functionality enabled
- Fixed excessive memory allocation that could occur when writing a chunk directly into a dataset and no size (concerning the data to be written) is specified (in this case, HDFql would have automatically set the size of the memory to the size of the dataset while it should have been set to the size of the chunk instead, which is usually (much) smaller)
- Fixed memory leak that could occur when reading a compound dataset/attribute that has a member of data type VARCHAR
- Fixed memory leak that could occur when freeing/finalizing a user-defined cursor populated with data (in the Java, Python and C# wrappers) - thanks to Bruno (University of Madeira, Portugal) for reporting this!

ISSUES
- The "FROM" redirecting option does not work properly when inserting variable-length data from memory into a dataset/attribute (in the Java, Python, C#, Fortran and R wrappers)
- The "WHERE" option (in the "SHOW" operation) does not work properly
- The writing/reading of a compound dataset/attribute does not support a per member operation (i.e. currently it only supports writing/reading all members of a compound)
- The writing of a compound dataset/attribute does not support direct values (e.g. "INSERT INTO my_compound VALUES(10, dummy, 5.6)")
- The "TOP", "BOTTOM", "FROM TO" and "STEP" post-processing options do not support compound datasets/attributes



=====================
2020/MAY/07
=====================
NEWS
- Released HDFql version 2.2.0
- Added support for compound datasets/attributes (see ISSUES section for current limitations - these will be removed in subsequent releases of HDFql) - thanks to James (ANSTO, Australia), Stuart (Brookhaven National Laboratory, USA), Igor (SCHOTT, Switzerland), Katy (CEA, France), Joshua (Idaho National Laboratory, USA) and Lucas (IBM, USA) for the feedback!
- Added support for enumeration datasets/attributes
- Removed debug static and shared libraries in distribution packages (as these were of little/no usage)
- Updated help functionality in HDFqlCLI (command-line interface)
- Updated reference manual - thanks to Cong-Han (National Formosa University, Taiwan) and Igor (SCHOTT, Switzerland) for the feedback!

CHANGES
- Added "SHOW MEMBER" operation (to enable showing members of an enumeration or a compound dataset/attribute)
- Added "SHOW OFFSET" operation (to enable showing offset of members of a compound dataset/attribute)
- Added "SET THREAD" operation (to enable setting the number of (CPU) threads that will be used when executing operations that support parallelism)
- Added "SHOW [MAX] THREAD" operation (to enable showing the number of (CPU) threads that will be used when executing operations that support parallelism)
- Added "LIMIT" option in the "INTO MEMORY" and "FROM MEMORY" redirecting options (to specify the number of elements to write/read into/from memory)
- Added "HDFQL_BITFIELD" constant
- Added "HDFQL_ENUMERATION" constant
- Added "HDFQL_COMPOUND" constant
- Updated "CREATE [DATASET | ATTRIBUTE]" operation (to enable creating an enumeration or a compound dataset/attribute)
- Updated "INSERT" operation (to enable writing an enumeration or a compound dataset/attribute)
- Updated "SELECT" operation (to enable reading an enumeration or a compound dataset/attribute)
- Updated "SHOW DATA TYPE" operation (to enable showing data type of members of an enumeration or a compound dataset/attribute)
- Updated "SHOW TAG" operation (to enable showing tags of members of a compound dataset/attribute)
- Updated "SHOW USE FILE" operation (to enable showing if a certain HDF5 file is used (i.e. opened) or not)
- Changed "SET CACHE" operation (to support 64 bit numbers for the slots and size cache parameters)
- Changed "SHOW CACHE" operation return data type to BIGINT when showing the slots or size cache parameters (previously the data type was INT)
- Changed "FLUSH", "CLOSE FILE", "CLOSE ALL FILE" and "CLOSE GROUP" operations (to raise an error - HDFQL_ERROR_NOT_OPEN - when no HDF5 file is in use)
- Changed "SIZE" functionality in the "INTO MEMORY" and "FROM MEMORY" redirecting options (the "SIZE" now specifies the size (in bytes) of the variable to write/read values into/from)
- Changed "HDFQL_REFERENCE" constant value to 67108864
- Removed "hdfql_cursor_get" and "hdfql_subcursor_get" functions (as these were of little/no usage)
- Removed "hdfql_subcursor_get_char" function (use "hdfql_subcursor_get_unsigned_tinyint" function instead)
- Removed "SHOW PCRE VERSION" operation (as it was unnecessary/out-of-scope)
- Removed "SHOW ZLIB VERSION" operation (as it was unnecessary/out-of-scope)
- Removed "HDFQL_ARRAY" constant (as it is covered by other constants)

FIXES
- Fixed issue (introduced in version 2.0.0) when writing direct values into a dataset/attribute of data type variable-length not working properly (in HDFql 32 bit distributions) - thanks to Mel (Engineering Technology Corporation, USA) for reporting this!
- Fixed issue (introduced in version 2.0.0) when writing direct values into a dataset/attribute of data type OPAQUE not working properly
- Fixed issue of the "SHOW [DATASET | ATTRIBUTE] SIZE" operation not working properly when object is an attribute of variable-length data type
- Fixed issue of automatic chunk sizes not being correctly calculated (in HDFql Windows 32 bit distributions)
- Fixed issue of the "hdfql_execute" function returning an incorrect status when the executed script is a comment and the previous executed script returned an error
- Fixed issue of the "RENAME FILE" operation overwriting an existing file even when the "TRUNCATE" keyword is not specified (in HDFql Linux and macOS distributions)
- Fixed issue of the "CREATE [DATASET | ATTRIBUTE]" operation not creating a scalar dataset or attribute when no dimensions are provided by the user (in this case, the dataset or attribute would have been (wrongly) created with one dimension of size 1)
- Fixed issue of the "hdfql_variable_register" and "hdfql_variable_transient_register" functions not working properly under certain circumstances (in the Python 64 bit wrapper) - thanks to Dennis (University of Augsburg, Germany) for reporting this!
- Fixed issue of the Python wrapper for version 3.7 not working properly (in Linux) - thanks to Dennis (University of Augsburg, Germany) and Leopold (University of Vienna, Austria) for reporting this!
- Fixed issue of the "FROM" redirecting option not working properly when inserting data from a text file into a dataset/attribute of data type CHAR, OPAQUE or VARCHAR under certain circumstances
- Fixed issue of the "hdfql_error_get_position" function not returning the correct error position in the script under certain circumstances (e.g. when executing "INSERT INTO my_dataset VALUES", instead of returning 30 the function was wrongly returning 3)
- Fixed issue of the "hdfql_variable_get_dimension_count" and "hdfql_variable_get_dimension" functions not returning correct values under certain circumstances
- Fixed crash when writing direct values into a dataset/attribute under certain circumstances (e.g. when executing "CREATE DATASET my_dataset AS INT(2, 3, 5) VALUES(, (10, 12, ,))")
- Fixed crash when post-processing "SHOW USE DIRECTORY", "SHOW USE FILE", "SHOW USE GROUP", "SHOW HDFQL VERSION", "SHOW HDF5 VERSION", "SHOW MPI VERSION" and "SHOW EXTERNAL LINK PREFIX" operations under certain circumstances (e.g. when executing "SHOW USE DIRECTORY FROM 1 TO 1")
- Fixed memory leak that could occur when creating a dataset or attribute of data type CHAR

ISSUES
- The "FROM" redirecting option does not work properly when inserting variable-length data from memory into a dataset/attribute (in the Java, Python, C#, Fortran and R wrappers)
- The "WHERE" option (in the "SHOW" operation) does not work properly
- The writing/reading of a compound dataset/attribute does not support a per member operation (i.e. currently it only supports writing/reading all members of a compound)
- The writing of a compound dataset/attribute does not support direct values (e.g. "INSERT INTO my_compound VALUES(10, dummy, 5.6)"), text files (e.g. "INSERT INTO my_compound VALUES FROM TEXT FILE my_file.txt") and binary files (e.g. "INSERT INTO my_compound VALUES FROM BINARY FILE my_file.bin")
- The "TOP", "BOTTOM", "FROM TO" and "STEP" post-processing options do not support compound datasets/attributes



=====================
2019/JUL/03
=====================
NEWS
- Released HDFql version 2.1.0
- Added support for direct chunk write/read into/from datasets (to greatly increase performance) - thanks to Mark (University of Chicago, USA), Xiaoqiang (Paul Scherrer Institute, Switzerland), Ulrik (Diamond Light Source, UK), Tobias (Imperial College London, UK) and Stefan (Fermilab, USA) for the feedback!
- Added wrapper for Python version 3.7.x
- Added capability to create intermediate directories when creating an HDF5 file (e.g. when creating the file "my_directory/my_subdirectory/my_file.h5", besides "my_file.h5" being created as a file, "my_directory" and "my_subdirectory" will be created as directories in case they do not exist)
- Added capability to open an HDF5 file, define/manipulate/query/introspect objects (i.e. groups, datasets, attributes, (soft) links or external links) and, afterwards, close the file in one go (in all relevant operations - e.g. "CREATE DATASET", "INSERT" and "SELECT")
- Updated help functionality in HDFqlCLI (command-line interface)
- Updated reference manual

CHANGES
- Added "hdfql_variable_transient_register" function (to enable a variable to be (1) registered for usage in a script and (2) automatically unregistered when the execution of the script has finished - through the "hdfql_execute" function)
- Added "hdfql_variable_unregister_all" function (to unregister all variables that have previously been registered in one go)
- Added package specification for the HDFql R functions that call the corresponding underlying HDFql C shared library functions - thanks to Michael (California Department of Water Resources, USA) for suggesting this!
- Added "SET [USE FILE] MPI ATOMIC" operation (to enable or disable atomic MPI operations)
- Added "SHOW [USE FILE] MPI ATOMIC" operation (to enable showing whether atomic MPI operations are enabled or disabled)
- Added "SET EXTERNAL LINK PREFIX" operation (to support the specification of a prefix that will be inserted at the beginning of an HDF5 file name when resolving external links)
- Added "SHOW EXTERNAL LINK PREFIX" operation (to enable showing the prefix that will be inserted at the beginning of an HDF5 file name when resolving external links)
- Added "SHOW MASK" operation (to enable showing the filter mask specified when writing a chunk directly into a dataset for the first time)
- Added "HDFQL_ERROR_UNEXPECTED_STORAGE_TYPE" constant
- Added "HDFQL_ERROR_DANGLING_LINK" constant
- Updated "USE FILE" operation (to enable opening an HDF5 file using atomic MPI operations)
- Updated "INSERT" operation (to enable writing hexadecimal numbers - e.g. when executing "INSERT INTO my_dataset VALUES(0xFF)", this operation will write 255 (i.e. 0xFF) into dataset "my_dataset")
- Updated "INSERT" operation (to enable direct chunk write)
- Updated "SELECT" operation (to enable direct chunk read)
- Updated "COPY" operation (to enable copying an object from an HDF5 file into another HDF5 file)
- Changed "ALTER DIMENSION" operation (to no longer require parenthesis to surround dimensions)
- Changed "HDFQL_ERROR_NOT_REGISTERED" constant value to -20
- Changed "HDFQL_ERROR_INVALID_REGULAR_EXPRESSION" constant value to -21
- Changed "HDFQL_EXTERNAL_LINK" constant value to 64
- Removed "HDFQL_HARD_LINK" constant (as it is covered by the "HDFQL_GROUP" and "HDFQL_DATASET" constants)
- Removed "RUN" operation (as it was unnecessary/out-of-scope)

FIXES
- Fixed issue (introduced in version 2.0.0) of attributes not being dropped (i.e. deleted) when using the "DROP" operation to remove all the objects (e.g. attributes) that a group or dataset may store
- Fixed handling of dangling soft and external links throughout HDFql operations not working properly
- Fixed crash when the number of new objects specified is lower than the number of objects to copy in the "COPY" operation
- Fixed memory leak that could occur when using the "SHOW DATA TYPE", "SHOW ENDIANNESS", "SHOW CHARSET", "SHOW TAG" and "SHOW [DATASET | ATTRIBUTE] SIZE" operations
- Fixed issue of the "CLOSE GROUP" operation not closing the group currently in use properly when the group is an external link
- Fixed issue of the "SHOW", "SHOW DIRECTORY" and "SHOW FILE" operations not working properly when redirecting results into memory (i.e. when using "INTO MEMORY" redirecting option)

ISSUES
- The "FROM" redirecting option does not work properly when inserting variable-length data from memory into a dataset/attribute (in the Java, Python, C#, Fortran and R wrappers)
- The "WHERE" option (in the "SHOW" operation) does not work properly
- The "SHOW [DATASET | ATTRIBUTE] SIZE" operation does not work properly when object is an attribute of variable-length data type



=====================
2019/APR/05
=====================
NEWS
- Released HDFql version 2.0.1
- Updated reference manual

CHANGES
- None

FIXES
- Fixed issue (introduced in version 2.0.0) of chunk sizes provided by the user not being respected (upon creation of a chunked dataset) - thanks to Gerhard for reporting this!
- Fixed issue of the "DEEP" option not always being respected in the "SHOW [GROUP | DATASET | ...] LIKE" and "DROP [GROUP | DATASET | ...] LIKE" operations
- Fixed crash when getting storage dimensions (i.e. when using "SHOW STORAGE DIMENSION" operation) of a dataset that is not chunked

ISSUES
- The "FROM" redirecting option does not work properly when inserting variable-length data from memory into a dataset/attribute (in the Java, Python, C#, Fortran and R wrappers)
- The "WHERE" option (in the "SHOW" operation) does not work properly
- The handling of dangling soft and external links throughout HDFql operations does not work properly
- The "SHOW [DATASET | ATTRIBUTE] SIZE" operation does not work properly when object is an attribute of variable-length data type



=====================
2019/MAR/27
=====================
NEWS
- Released HDFql version 2.0.0
- Added support for parallel HDF5 (Linux and macOS only - Windows will be supported pending user interest) - thanks to Quincey (Berkeley Lab, USA), Rob (Argonne Lab, USA), Konrad (CNRS, France), Sebastian (Juelich Supercomputing Centre, Germany), Guy (IN2P3, France) and Holger (Fermilab, USA) for the feedback!
- Added wrapper for the Intel Fortran Compiler (IFORT) (Windows and Linux only - macOS will be supported pending user interest) - thanks to Intel for sponsoring HDFql with a free IFORT license!
- Added automatic calculation of chunk sizes when these are not provided by the user (upon creation of a chunked dataset)
- Added capability to create intermediate groups when creating a dataset (e.g. when creating the dataset "my_group/my_subgroup/my_dataset", besides "my_dataset" being created as a dataset, "my_group" and "my_subgroup" will be created as groups in case they do not exist)
- Added capability to specify the storage allocation when creating a dataset (i.e. early, incremental or late)
- Improved support for 64 bit architecture (see CHANGES and FIXES sections)
- Improved performance and memory footprint when writing/reading values into/from datasets/attributes from/into memory
- Removed dependencies of HDF5 and ANTLR header files in the HDFql C header file (to eliminate potential declaration conflicts between HDF5 or ANTLR header files and other dependencies when working with HDFql in C or C++)
- Updated help functionality in HDFqlCLI (command-line interface)
- Updated reference manual - thanks to Jeff (Redwood Center for Theoretical Neuroscience, USA) for the feedback!
- Updated HDF5 library in use to 1.8.21 (previously HDFql was using version 1.8.19)

CHANGES
- Added "hdfql_mpi_get_size" function (to get MPI size)
- Added "hdfql_mpi_get_rank" function (to get MPI rank)
- Added "SHOW MPI VERSION" operation (to enable showing the version of the MPI library used by HDFql)
- Added "SHOW STORAGE ALLOCATION" operation (to enable showing the storage allocation of a dataset)
- Added "SHOW FILL TYPE" operation (to enable showing the fill type of a dataset)
- Added "SHOW FILL VALUE" operation (to enable showing the fill value of a dataset)
- Added "HDFQL_ARRAY" constant
- Added "HDFQL_REFERENCE" constant
- Added "HDFQL_EARLY" constant
- Added "HDFQL_INCREMENTAL" constant
- Added "HDFQL_LATE" constant
- Added "HDFQL_FILL_DEFAULT" constant
- Added "HDFQL_FILL_USER_DEFINED" constant
- Added "HDFQL_FILL_UNDEFINED" constant
- Added "HDFQL_ERROR_NOT_SUPPORTED" constant
- Added "TOP", "BOTTOM", "FROM TO" and "STEP" post-processing options in the "SELECT" operation (these were removed in HDFql version 1.3.0 but have been considered to be useful after all)
- Updated "CREATE FILE" operation (to enable creating an HDF5 file in a parallel way)
- Updated "USE FILE" operation (to enable opening an HDF5 file in a parallel way)
- Updated "INSERT" operation (to enable writing values into a dataset in a parallel way)
- Updated "SELECT" operation (to enable reading values from a dataset in a parallel way)
- Updated "CREATE DATASET" operation (to enable specifying the storage allocation - i.e. early, incremental or late)
- Updated "CREATE DATASET" operation (to enable setting fill values)
- Updated "RENAME" operation (to enable renaming objects of type soft or external link in an explicit way)
- Updated "COPY" operation (to enable copying objects of type soft or external link in an explicit way)
- Updated "DROP" operation (to enable deleting objects of type soft or external link in an explicit way)
- Updated "SHOW" operation (to enable returning objects of type soft or external link in an explicit way)
- Updated "SHOW TYPE" operation (to enable returning the object type when it is both a group or dataset and a soft or external link)
- Changed the way a result set of data type CHAR is stored in and retrieved from a cursor (to retrieve a result set, use the "hdfql_subcursor_get_char" function)
- Changed the way a result set of data type OPAQUE is stored in and retrieved from a cursor (to retrieve a result set, use the "hdfql_subcursor_get_unsigned_tinyint" function)
- Changed maximum number of variables that can be registered at any given time to 8 in order to increase performance (previously the maximum number was 16, which was unnecessarily high)
- Changed filter specification order in the "CREATE DATASET" operation
- Changed "SHOW STORAGE DIMENSION" operation return data type to BIGINT (previously the data type was INT)
- Changed "SHOW DIMENSION" operation return data type to BIGINT (previously the data type was INT)
- Changed "SHOW MAX DIMENSION" operation return data type to BIGINT (previously the data type was INT)
- Changed "HDFQL_ERROR_NOT_ENOUGH_SPACE" constant value to -7
- Changed "HDFQL_ERROR_NOT_ENOUGH_MEMORY" constant value to -8
- Changed "HDFQL_ERROR_ALREADY_EXISTS" constant value to -9
- Changed "HDFQL_ERROR_EMPTY" constant value to -10
- Changed "HDFQL_ERROR_FULL" constant value to -11
- Changed "HDFQL_ERROR_BEFORE_FIRST" constant value to -12"
- Changed "HDFQL_ERROR_AFTER_LAST" constant value to -13"
- Changed "HDFQL_ERROR_OUTSIDE_LIMIT" constant value to -14"
- Changed "HDFQL_ERROR_NO_ADDRESS" constant value to -15"
- Changed "HDFQL_ERROR_UNEXPECTED_TYPE" constant value to -16"
- Changed "HDFQL_ERROR_UNEXPECTED_DATA_TYPE" constant value to -17"
- Changed "HDFQL_ERROR_NOT_REGISTERED" constant value to -18"
- Changed "HDFQL_ERROR_INVALID_REGULAR_EXPRESSION" constant value to -19"
- Renamed "hdfql_cursor_get_datatype" function to "hdfql_cursor_get_data_type"
- Renamed "hdfql_variable_get_datatype" function to "hdfql_variable_get_data_type"
- Renamed "SHOW HDF VERSION" operation to "SHOW HDF5 VERSION"
- Renamed "HDFQL_ERROR_UNEXPECTED_DATATYPE" constant to "HDFQL_ERROR_UNEXPECTED_DATA_TYPE"
- Removed "SHOW RELEASE DATE" operation (as it was unnecessary/out-of-scope)
- Removed "SHOW MAC ADDRESS" operation (as it was unnecessary/out-of-scope)
- Removed "HDFQL_NATIVE_ENDIAN" constant (as it is covered by the "HDFQL_LITTLE_ENDIAN" and "HDFQL_BIG_ENDIAN" constants)
- Removed need to include code snippet "System.loadLibrary("HDFql");" in a Java program (as the HDFql shared library is automatically loaded when importing the HDFql Java package now)
- Removed need to call the "LOC" function to get the address of a variable when using "hdfql_variable_*" functions in a Fortran program (as the HDFql Fortran wrapper can automatically retrieve the address of a variable now)

FIXES
- Fixed crash (introduced in version 1.5.0) when the result of a DIL operation is redirected into memory (in the Java wrapper) - thanks to Romain (CEA, France) for reporting this!
- Fixed memory leak (introduced in version 1.5.0) when the result of a "SELECT" operation is redirected into memory (in the Java wrapper)
- Fixed the "ORDER" post-processing option not working properly when ordering reversely
- Fixed issue of values of data type BIGINT being truncated into a data type INT when inserting these into a dataset/attribute - thanks to Erik (M+P, The Netherlands) and Ryan (KMLabs, USA) for reporting this!
- Fixed issue of number returned by the "variableGetNumber" function not being correctly calculated (in the Java wrapper)
- Fixed issue of number returned by the "VariableGetNumber" function not being correctly calculated (in the C# wrapper)
- Fixed crash when reading a dataset/attribute of data type CHAR and redirecting results into memory (in the R wrapper) - thanks to Michael (U.S. Army Corps of Engineers, USA) for reporting this!
- Fixed issue of creating an external link pointing to the root (i.e. "/") of an external HDF5 file not working properly
- Fixed issue of the "FROM" redirecting option not taking into account subseparator when inserting variable-length data from a text file into a dataset/attribute
- Fixed issue of the "FROM" redirecting option not working properly when inserting variable-length data from a binary file into a dataset/attribute
- Fixed crash when redirecting results into a user-defined cursor (in the Fortran wrapper for macOS)
- Fixed issue of redirecting results from a dataset/attribute of data type OPAQUE with two or more dimensions into a file
- Fixed issue of the "ORDER" option not working in the "SELECT" operation
- Fixed crash when releasing memory reserved by a user-defined cursor upon its finalization (in the R wrapper for macOS)
- Fixed issue of not converting correctly between FLOAT|DOUBLE to TINYINT|SMALLINT|INT|BIGINT (when using the cursor to insert data into a dataset/attribute)
- Fixed issue of truncating the last character of a dataset/attribute of data type CHAR when reading it - thanks to Petr (University of West Bohemia, Czech Republic) for reporting this!
- Fixed issue of not being able to rename/copy an attribute of data type OPAQUE into another location (i.e. group or dataset)
- Fixed crash that could occur when working with the "hdfql_error_get_message", "hdfql_cursor_get_char" and "hdfql_subcursor_get_char" functions (in the Fortran wrapper)

ISSUES
- The "FROM" redirecting option does not work properly when inserting variable-length data from memory into a dataset/attribute (in the Java, Python, C#, Fortran and R wrappers)
- The "WHERE" option (in the "SHOW" operation) does not work properly
- The handling of dangling soft and external links throughout HDFql operations does not work properly
- The "SHOW [DATASET | ATTRIBUTE] SIZE" operation does not work properly when object is an attribute of variable-length data type



=====================
2017/DEC/11
=====================
NEWS
- Released HDFql version 1.5.0
- Added wrapper for R
- Added support for irregular hyperslab and point selections for writing or reading datasets
- Added library bounds settings for creating or opening files
- Improved support for 64 bit architecture (see CHANGES and FIXES sections)
- Updated error reporting mechanism to use new error constants (see CHANGES section)
- Updated help functionality in HDFqlCLI (command-line interface)
- Updated reference manual
- Updated HDF5 library in use to 1.8.19 (previously HDFql was using version 1.8.16)

CHANGES
- Added "SET LIBRARY BOUNDS" operation (to enable setting bounds on HDF5 library versions and indirectly format versions when creating objects)
- Added "SHOW LIBRARY BOUNDS" operation (to enable showing the bounds on HDF5 library versions and indirectly format versions when creating objects)
- Added "SET FLUSH" operation
- Added "SET DEBUG" operation
- Added "FROM TO" post-processing option
- Added "HDFQL_UNLIMITED" constant
- Added "HDFQL_EARLIEST" constant
- Added "HDFQL_LATEST" constant
- Added "HDFQL_VERSION_18" constant
- Added "HDFQL_ERROR_NOT_OPEN" constant
- Added "HDFQL_ERROR_INVALID_FILE" constant
- Added "HDFQL_ERROR_NOT_ENOUGH_SPACE" constant
- Added "HDFQL_ERROR_NOT_ENOUGH_MEMORY" constant
- Added "HDFQL_ERROR_UNEXPECTED_TYPE" constant
- Added "HDFQL_ERROR_UNEXPECTED_DATATYPE" constant
- Added "HDFQL_ERROR_INVALID_REGULAR_EXPRESSION" constant
- Updated "CREATE FILE" operation (to enable setting bounds on HDF5 library versions when creating an HDF5 file)
- Updated "USE FILE" operation (to enable setting bounds on HDF5 library versions when opening an HDF5 file)
- Updated "INSERT" and "SELECT" operations (to enable irregular hyperslab and point selections) - thanks to Leng (CH2M, USA) for testing these!
- Changed base position of the first element stored in a cursor to 0 (previously it was 1)
- Changed "HDFQL_ERROR_ALREADY_EXISTS" constant value to -8"
- Changed "HDFQL_ERROR_EMPTY" constant value to -9"
- Changed "HDFQL_ERROR_FULL" constant value to -10"
- Changed "HDFQL_ERROR_BEFORE_FIRST" constant value to -11"
- Changed "HDFQL_ERROR_AFTER_LAST" constant value to -12"
- Changed "HDFQL_ERROR_OUTSIDE_LIMIT" constant value to -13"
- Changed "HDFQL_ERROR_NO_ADDRESS" constant value to -14"
- Changed "HDFQL_ERROR_NOT_REGISTERED" constant value to -17"
- Changed Java wrapper package to "as.hdfql" (previously the wrapper was in the default package) - thanks to Romain (CEA, France) and Petr (UC Berkeley, USA) for suggesting this!
- Changed C# wrapper namespace to "AS.HDFql" (previously the wrapper was in the global namespace)
- Removed "ENABLE FLUSH" operation (use "SET FLUSH" operation instead)
- Removed "DISABLE FLUSH" operation (use "SET FLUSH" operation instead)
- Removed "ENABLE DEBUG" operation (use "SET DEBUG" operation instead)
- Removed "DISABLE DEBUG" operation (use "SET DEBUG" operation instead)
- Removed need to append CHAR(0) to the script that will be executed when using the "hdfql_execute" function (in the Fortran wrapper)

FIXES
- Fixed issue of registering a variable with a memory address above 32 bit in the "VariableRegister" function (in the C# wrapper) - thanks to Christian (Daimler AG, Germany) for reporting this!
- Fixed issue of regular expressions not being properly processed (it was causing an unpredictable behavior when using the "LIKE" option) - thanks to Petr (UC Berkeley, USA) for reporting this!
- Fixed issue of the "USE FILE" operation not being able to open an HDF5 file when its size is greater than 2^32 bytes (in Windows) - thanks to Christian (Daimler AG, Germany) for reporting this!
- Fixed issue of the "SHOW FILE SIZE" operation not reporting properly the size of an HDF5 file when it is greater than 2^32 bytes (in Windows)
- Fixed issue of the "SHOW [DATASET | ATTRIBUTE] SIZE" operation not reporting properly the size of an dataset/attribute when its size is greater than 2^32 bytes
- Fixed issue of the "SHOW DIMENSION" operation not reporting properly the size of a dimension when greater than 2^32
- Fixed issue of the "SHOW MAX DIMENSION" operation not reporting properly the size of a maximum dimension when greater than 2^32
- Fixed issue of the "INSERT" operation not working properly if inserting data into two or more datasets that all have hyperslab defined
- Fixed crash when writing values into a dataset from memory using hyperslab without the "SIZE" keyword being specified
- Fixed issue of a dataset or attribute of data type BIGINT being truncated into a data type INT when reading and redirecting it into memory (in the Java wrapper)
- Fixed issue of number returned by "hdfql_variable_get_number" function not being correctly calculated (in the Fortran wrapper)

ISSUES
- The "FROM" redirecting option does not work properly when inserting variable-length data from a binary file or memory into a dataset/attribute
- The "ORDER" post-processing option does not work properly when ordering reversely
- The "WHERE" option (in the "SHOW" operation) does not work properly
- The handling of dangling soft and external links throughout HDFql operations does not work properly
- The "SHOW [DATASET | ATTRIBUTE] SIZE" operation does not work properly when object is an attribute of variable-length data type



=====================
2017/MAR/21
=====================
NEWS
- Released HDFql version 1.4.0
- Added wrapper for Fortran (Linux and macOS only - Windows will be supported pending user interest)
- Added wrapper for C++
- Added debug static and shared libraries in distribution packages
- Resumed availability of distribution packages for macOS
- Refactored function/method signatures of the Java, Python and C# wrappers (to be more user friendly when displayed in IDEs' code completion pop-up window)
- Updated error reporting mechanism to use new error constants (see CHANGES section)
- Updated help functionality in HDFqlCLI (command-line interface)
- Updated reference manual

CHANGES
- Added "HDFQL_ERROR_NOT_FOUND" constant
- Added "HDFQL_ERROR_NO_ACCESS" constant
- Added "HDFQL_ERROR_ALREADY_EXISTS" constant
- Added "HDFQL_ERROR_EMPTY" constant
- Added "HDFQL_ERROR_FULL" constant
- Added "HDFQL_ERROR_BEFORE_FIRST" constant
- Added "HDFQL_ERROR_AFTER_LAST" constant
- Added "HDFQL_ERROR_NO_ADDRESS" constant
- Added "HDFQL_ERROR_NOT_REGISTERED" constant
- Added "HDFQL_ERROR_OUTSIDE_LIMIT" constant
- Added "HDFQL_ERROR_UNKNOWN" constant
- Renamed "hdfql_execute_status" function to "hdfql_execute_get_status"
- Renamed "hdfql_error_line" function to "hdfql_error_get_line"
- Renamed "hdfql_error_position" function to "hdfql_error_get_position"
- Renamed "hdfql_error_message" function to "hdfql_error_get_message"
- Changed "HDFQL_ERROR_PARSE" constant value to -1"
- Removed "HDFQL_ERROR" constant as it was too generic (replaced by more meaningful error constants)
- Removed parameter "cursor_clone_clear" from "hdfql_cursor_clone" function as the cursor that will be a clone is now always cleared at the start

FIXES
- Fixed crash when writing values into a dataset from memory using hyperslab
- Fixed crash when writing values into a dataset/attribute from memory that was not properly initialized (in the Java wrapper)
- Fixed crash when redirecting results to memory that was not previously registered (i.e. when using "INTO MEMORY" redirecting option)
- Fixed issue of the "hdfql_error_get_position" function not returning the correct error position as of the second line of the script

ISSUES
- The "FROM" redirecting option does not work properly when inserting variable-length data from a binary file or memory into a dataset/attribute
- The "ORDER" post-processing option does not work properly when ordering reversely
- The "WHERE" option (in the "SHOW" operation) does not work properly
- The handling of dangling soft and external links throughout HDFql operations does not work properly
- The "SHOW [DATASET | ATTRIBUTE] SIZE" operation does not work properly when object is an attribute of variable-length data type



=====================
2016/OCT/31
=====================
NEWS
- Released HDFql version 1.3.0
- Added support for opaque data types
- Added support for showing objects by their creation order
- Added support for renaming/moving directories
- Added error reporting mechanism
- Added wrapper for Python version 3.5.x
- Updated help functionality in HDFqlCLI (command-line interface)
- Updated reference manual

CHANGES
- Added "SHOW TAG" operation (to enable showing the tag associated with a dataset/attribute of an opaque data type)
- Added "SHOW ORDER" operation (to enable showing if the creation order in a group or dataset is being tracked or indexed)
- Added "RENAME DIRECTORY" operation (to enable renaming/moving directories)
- Added "hdfql_error_line", "hdfql_error_position" and "hdfql_error_message" functions (to ease debugging errors)
- Updated "CREATE DATASET" operation (to enable creating a dataset of an opaque data type)
- Updated "CREATE ATTRIBUTE" operation (to enable creating an attribute of an opaque data type)
- Updated "SHOW" operation (to enable showing objects by their creation order)
- Updated "hdfql_variable_register" function (it now returns the number assigned to the registered variable instead of HDFQL_SUCCESS)
- Removed "TOP", "BOTTOM" and "STEP" post-processing options in the "SELECT" operation (these have become redundant due to hyperslab)

FIXES
- Fixed issue of creating intermediate directories in one go (in "CREATE DIRECTORY" operation)
- Fixed issue of renaming attributes when data type is variable-length (in "RENAME [GROUP | DATASET | ATTRIBUTE]" operation)
- Fixed issue of the "DEEP" option to accept optional parameters
- Fixed issue of writing/reading values into/from datasets/attributes that are encoded as UTF8 strings (i.e. HDFql UTF8 CHAR or UTF8 VARCHAR data types)
- Fixed issue of the "hdfql_variable_get_*" functions not returning proper values after executing a redirected "SELECT" or "SHOW" operation into memory

ISSUES
- The "FROM" redirecting option does not work properly when inserting variable-length data from a binary file or memory into a dataset/attribute
- The "ORDER" post-processing option does not work properly when ordering reversely
- The "WHERE" option (in the "SHOW" operation) does not work properly



=====================
2016/JUN/23
=====================
NEWS
- Released HDFql version 1.2.0
- Released simplified user license
- Added support for Microsoft Visual Studio 2015
- Added support for extendible datasets
- Added support for regular hyperslab selection
- Updated help functionality in HDFqlCLI (command-line interface)
- Updated reference manual

CHANGES
- Added "ALTER DIMENSION" operation (to enable changing dimensions of extendible datasets)
- Added "SHOW MAX DIMENSION" operation (to enable retrieving maximum dimensions of datasets)
- Updated "CREATE DATASET" operation (to enable extendible datasets)
- Updated "INSERT" and "SELECT" operations (to enable regular hyperslab selection)
- Renamed "ENABLE CACHE" operation to "SET CACHE"
- Removed "DISABLE CACHE" operation

FIXES
- Fixed issue of the "DROP" operation not working properly when object is a dangling soft or external link

ISSUES
- The "FROM" redirecting option does not work properly when inserting variable-length data from a binary file or memory into a dataset/attribute
- The "ORDER" post-processing option does not work properly when ordering reversely
- The "WHERE" option (in the "SHOW" operation) does not work properly



=====================
2016/MAY/31
=====================
NEWS
- Released HDFql version 1.1.1
- Updated help functionality in HDFqlCLI (command-line interface)
- Updated reference manual

CHANGES
- Added "HDFQL_SOFT_LINK" constant
- Added "HDFQL_HARD_LINK" constant
- Added "HDFQL_EXTERNAL_LINK" constant

FIXES
- Fixed issue of the "ORDER" post-processing option not working properly when ordering ascendingly
- Fixed issue of the "SHOW" operation not working properly when a soft or external link is dangling
- Fixed parsing issue (e.g. parsing "FLUSH invalid_keyword" was being incorrectly accepted)
- Fixed issue of the "execute" function not working properly with UNICODE strings (in the Python wrapper)
- Fixed crash when reading a dataset with the debug functionality enabled

ISSUES
- The "FROM" redirecting option does not work properly when inserting variable-length data from a file or memory into a dataset/attribute
- The "ORDER" post-processing option does not work properly when ordering reversely
- The "WHERE" option (in the "SHOW" operation) does not work properly



=====================
2016/APR/26
=====================
NEWS
- Released HDFql version 1.1.0
- Added support for Microsoft Visual Studio 2013
- Added cache parameter settings for when accessing files or datasets
- Added launchers to facilitate execution of HDFqlCLI (command-line interface)
- Added help functionality in HDFqlCLI
- Updated reference manual

CHANGES
- Added "ENABLE CACHE" operation
- Added "DISABLE CACHE" operation
- Added "SHOW CACHE" operation
- Added "HDFQL_DIRECTORY" constant
- Added "HDFQL_FILE" constant
- Renamed "SHOW DATATYPE [DATASET | ATTRIBUTE]" operation to "SHOW [DATASET | ATTRIBUTE] DATATYPE"
- Renamed "SHOW ENDIANNESS [DATASET | ATTRIBUTE]" operation to "SHOW [DATASET | ATTRIBUTE] ENDIANNESS"
- Renamed "SHOW CHARSET [DATASET | ATTRIBUTE]" operation to "SHOW [DATASET | ATTRIBUTE] CHARSET"
- Renamed "SHOW DIMENSION [DATASET | ATTRIBUTE]" operation to "SHOW [DATASET | ATTRIBUTE] DIMENSION"
- Renamed "SHOW SIZE [DATASET | ATTRIBUTE]" operation to "SHOW [DATASET | ATTRIBUTE] SIZE"
- Renamed "SHOW FLUSH STATUS" operation to "SHOW FLUSH"
- Renamed "SHOW DEBUG STATUS" operation to "SHOW DEBUG"
- Changed "HDFQL_GROUP" constant value to 4
- Changed "HDFQL_DATASET" constant value to 8
- Changed "HDFQL_ATTRIBUTE" constant value to 16

FIXES
- Fixed crash when redirecting results to memory (i.e. when using "INTO MEMORY" redirecting option)
- Fixed issue when parsing certain fractional numbers' representation (e.g. .5 was not recognized)
- Fixed "SHOW MAC ADDRESS" operation (was not returning all MAC addresses of the machine)
- Fixed issue of creating multiple (soft, hard or external) links in one go
- Fixed issue of HDFql reference manual not being included in distribution packages

ISSUES
- The "ORDER" post-processing option does not work properly when ordering ascendingly
- The "WHERE" option (in the "SHOW" operation) does not work properly



=====================
2016/MAR/23
=====================
NEWS
- Released HDFql version 1.0.0

CHANGES
- None

FIXES
- None

ISSUES
- None

